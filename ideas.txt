Dear Professors,

We have implemented a script that takes the data coded with the format specified in the document by noaa. Here is an example of decoded record and in attachment there is a full decoded record from one station:
usaf_id: 010010
date: 20160101
gmt: 0000
data source: 4
lat: 70.933
long: -8.667
elev: +0009
air_temp: 2.7
sea_lev: 09972
prechrs: 06
precdep: 0.0
usaf_id: 010010
date: 20160101
gmt: 0100
data source: 4
lat: 70.933
long: -8.667
elev: +0009
air_temp: 2.6
sea_lev: 09974
usaf_id: 010010
date: 20160101
gmt: 0200
data source: 4
lat: 70.933
long: -8.667
elev: +0009
air_temp: 2.5
sea_lev: 09973

We have parsed all the mandatory fields, to understand if there was any ordering of the data. The data are divided into groups by years. Each year contains a file for each station that recorded some data in that year. Inside each file the records are ordered by date and time.
We have also normalized the values to their correct unit-measure by dividing them with scaling factor provided in the document (e.g. the temperature had to be divided by 10). We have identified and changed the values representing empty values to empty values.
Then we selected all the data that can be useful for getting information about the global warming. The interesting ones are: location, date, air temperature, sea level and liquid precipitation.


We want to calculate average, median, max, min of the weather data (temperature, sea level and precipitation) for each station. To do that we compute the results for various date range. For example we want to calculate statistics for each station (which set a position in the world) for each day, month and year. In this way the computation is easier (we can use the result of daily max and min to calculate the monthly ones and the monthly for the yearly).

The tools we have planned to use for the moment are only Spark and HDFS. The computations are simple, they don't need any particular machine learning algorithm, graph processing tool or to analyze streaming data. Also the data structure is not very complex so we decide that using a tool like Spark SQL was unnecessary.

For the user interface we plan to use Google maps, showing on top of it a heatmap that shows the different statistics of temperature and some indicators to shows irregular changes in the sea level and precipitations.
For example we want to show in red the areas in the world were the average temperature in the years increased in the year range set by the user. We could also add the percentage of places where the average increased compared to those where it decreased. A percentage much higher than 50% would be a good indication of global warming (assuming the stations are well distributed on the planet).
We plan to give also the feature of pressing in one point of the map to see the textual statistics for that particular area. The map will let the user also to change the statistic that is currently displayed and the data range of the statistic.
The map will be displayed in a web browser. So we will use a web framework to build the application.

Kind Regards,
Group 6